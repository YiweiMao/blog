
@article{rew_netcdf_1990,
	title = {{NetCDF}: an interface for scientific data access},
	volume = {10},
	issn = {1558-1756},
	shorttitle = {{NetCDF}},
	doi = {10.1109/38.56302},
	abstract = {The network common data form (NetCDF), a data abstraction for storing and retrieving multidimensional data, is described. NetCDF is distributed as a software library that provides a concrete implementation of that abstraction. The implementation provides a machine-independent format for representing scientific data. Together, the abstraction, library, and data format support the creation, access, and sharing of scientific information. NetCDF is useful for supporting objects that contain dissimilar kinds of data in a heterogeneous network environment and for writing application software that does not depend on application-specific formats. Independence from particular machine representations is achieved by using a nonproprietary standard for external data representation. The discussion covers NetCDF data abstraction and interface; dimensions, variables, and attributes; direct access and hyperslab access, the NetCDF library; the data format; ncdump and ncgen utilities; experience, usability, and performance; limitations of NetCDF; and future plans.{\textless}{\textgreater}},
	number = {4},
	journal = {IEEE Computer Graphics and Applications},
	author = {Rew, R. and Davis, G.},
	month = jul,
	year = {1990},
	note = {Conference Name: IEEE Computer Graphics and Applications},
	keywords = {Application software, Computer architecture, Computer displays, Data visualization, Educational institutions, Information retrieval, Meteorology, Multidimensional systems, NetCDF, Software libraries, Workstations, application software, attributes, computer graphics, data abstraction, data structures, dimensions, direct access, external data representation, heterogeneous network environment, hyperslab access, multidimensional data, network operating systems, scientific data access, software library, standard, variables},
	pages = {76--82}
}

@article{aasen_quantitative_2018,
	title = {Quantitative {Remote} {Sensing} at {Ultra}-{High} {Resolution} with {UAV} {Spectroscopy}: {A} {Review} of {Sensor} {Technology}, {Measurement} {Procedures}, and {Data} {Correction} {Workflows}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Quantitative {Remote} {Sensing} at {Ultra}-{High} {Resolution} with {UAV} {Spectroscopy}},
	url = {https://www.mdpi.com/2072-4292/10/7/1091},
	doi = {10.3390/rs10071091},
	abstract = {In the last 10 years, development in robotics, computer vision, and sensor technology has provided new spectral remote sensing tools to capture unprecedented ultra-high spatial and high spectral resolution with unmanned aerial vehicles (UAVs). This development has led to a revolution in geospatial data collection in which not only few specialist data providers collect and deliver remotely sensed data, but a whole diverse community is potentially able to gather geospatial data that fit their needs. However, the diversification of sensing systems and user applications challenges the common application of good practice procedures that ensure the quality of the data. This challenge can only be met by establishing and communicating common procedures that have had demonstrated success in scientific experiments and operational demonstrations. In this review, we evaluate the state-of-the-art methods in UAV spectral remote sensing and discuss sensor technology, measurement procedures, geometric processing, and radiometric calibration based on the literature and more than a decade of experimentation. We follow the \&lsquo;journey\&rsquo; of the reflected energy from the particle in the environment to its representation as a pixel in a 2D or 2.5D map, or 3D spectral point cloud. Additionally, we reflect on the current revolution in remote sensing, and identify trends, potential opportunities, and limitations.},
	language = {en},
	number = {7},
	urldate = {2020-09-22},
	journal = {Remote Sensing},
	author = {Aasen, Helge and Honkavaara, Eija and Lucieer, Arko and Zarco-Tejada, Pablo J.},
	month = jul,
	year = {2018},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {2D imager, Remotely Piloted Aircraft Systems (RPAS), calibration, drone, hyperspectral, imaging spectroscopy, low-altitude, multispectral, pushbroom, remote sensing, sensors, snapshot, spectral, spectroradiometers, unmanned aerial systems (UAS), unmanned aerial vehicles},
	pages = {1091}
}

@article{windrim_unsupervised_2019,
	title = {Unsupervised {Feature}-{Learning} for {Hyperspectral} {Data} with {Autoencoders}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2072-4292/11/7/864},
	doi = {10.3390/rs11070864},
	abstract = {This paper proposes novel autoencoders for unsupervised feature-learning from hyperspectral data. Hyperspectral data typically have many dimensions and a significant amount of variability such that many data points are required to represent the distribution of the data. This poses challenges for higher-level algorithms which use the hyperspectral data (e.g., those that map the environment). Feature-learning mitigates this by projecting the data into a lower-dimensional space where the important information is either preserved or enhanced. In many applications, the amount of labelled hyperspectral data that can be acquired is limited. Hence, there is a need for feature-learning algorithms to be unsupervised. This work proposes unsupervised techniques that incorporate spectral measures from the remote-sensing literature into the objective functions of autoencoder feature learners. The proposed techniques are evaluated on the separability of their feature spaces as well as on their application as features for a clustering task, where they are compared against other unsupervised feature-learning approaches on several different datasets. The results show that autoencoders using spectral measures outperform those using the standard squared-error objective function for unsupervised hyperspectral feature-learning.},
	language = {en},
	number = {7},
	urldate = {2020-09-22},
	journal = {Remote Sensing},
	author = {Windrim, Lloyd and Ramakrishnan, Rishi and Melkumyan, Arman and Murphy, Richard J. and Chlingaryan, Anna},
	month = jan,
	year = {2019},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {autoencoders, deep learning, hyperspectral, unsupervised feature-learning},
	pages = {864}
}

@article{swayze_effects_2003,
	title = {Effects of spectrometer band pass, sampling, and signal-to-noise ratio on spectral identification using the {Tetracorder} algorithm},
	volume = {108},
	copyright = {Copyright 2003 by the American Geophysical Union.},
	issn = {2156-2202},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2002JE001975},
	doi = {10.1029/2002JE001975},
	abstract = {Estimates of spectrometer band pass, sampling interval, and signal-to-noise ratio required for identification of pure minerals and plants were derived using reflectance spectra convolved to AVIRIS, HYDICE, MIVIS, VIMS, and other imaging spectrometers. For each spectral simulation, various levels of random noise were added to the reflectance spectra after convolution, and then each was analyzed with the Tetracorder spectral identification algorithm [Clark et al., 2003]. The outcome of each identification attempt was tabulated to provide an estimate of the signal-to-noise ratio at which a given percentage of the noisy spectra were identified correctly. Results show that spectral identification is most sensitive to the signal-to-noise ratio at narrow sampling interval values but is more sensitive to the sampling interval itself at broad sampling interval values because of spectral aliasing, a condition when absorption features of different materials can resemble one another. The band pass is less critical to spectral identification than the sampling interval or signal-to-noise ratio because broadening the band pass does not induce spectral aliasing. These conclusions are empirically corroborated by analysis of mineral maps of AVIRIS data collected at Cuprite, Nevada, between 1990 and 1995, a period during which the sensor signal-to-noise ratio increased up to sixfold. There are values of spectrometer sampling and band pass beyond which spectral identification of materials will require an abrupt increase in sensor signal-to-noise ratio due to the effects of spectral aliasing. Factors that control this threshold are the uniqueness of a material's diagnostic absorptions in terms of shape and wavelength isolation, and the spectral diversity of the materials found in nature and in the spectral library used for comparison. Array spectrometers provide the best data for identification when they critically sample spectra. The sampling interval should not be broadened to increase the signal-to-noise ratio in a photon-noise-limited system when high levels of accuracy are desired. It is possible, using this simulation method, to select optimum combinations of band-pass, sampling interval, and signal-to-noise ratio values for a particular application that maximize identification accuracy and minimize the volume of imaging data.},
	language = {en},
	number = {E9},
	urldate = {2020-09-22},
	journal = {Journal of Geophysical Research: Planets},
	author = {Swayze, Gregg A. and Clark, Roger N. and Goetz, Alexander F. H. and Chrien, Thomas G. and Gorelick, Noel S.},
	year = {2003},
	note = {\_eprint: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2002JE001975},
	keywords = {Imaging spectroscopy, Tetracorder, mineral map, signal-to-noise ratio, spectral band pass, spectral sampling}
}

@article{clark_imaging_2003,
	title = {Imaging spectroscopy: {Earth} and planetary remote sensing with the {USGS} {Tetracorder} and expert systems},
	volume = {108},
	copyright = {Copyright 2003 by the American Geophysical Union.},
	issn = {2156-2202},
	shorttitle = {Imaging spectroscopy},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2002JE001847},
	doi = {10.1029/2002JE001847},
	abstract = {Imaging spectroscopy is a tool that can be used to spectrally identify and spatially map materials based on their specific chemical bonds. Spectroscopic analysis requires significantly more sophistication than has been employed in conventional broadband remote sensing analysis. We describe a new system that is effective at material identification and mapping: a set of algorithms within an expert system decision-making framework that we call Tetracorder. The expertise in the system has been derived from scientific knowledge of spectral identification. The expert system rules are implemented in a decision tree where multiple algorithms are applied to spectral analysis, additional expert rules and algorithms can be applied based on initial results, and more decisions are made until spectral analysis is complete. Because certain spectral features are indicative of specific chemical bonds in materials, the system can accurately identify and map those materials. In this paper we describe the framework of the decision making process used for spectral identification, describe specific spectral feature analysis algorithms, and give examples of what analyses and types of maps are possible with imaging spectroscopy data. We also present the expert system rules that describe which diagnostic spectral features are used in the decision making process for a set of spectra of minerals and other common materials. We demonstrate the applications of Tetracorder to identify and map surface minerals, to detect sources of acid rock drainage, and to map vegetation species, ice, melting snow, water, and water pollution, all with one set of expert system rules. Mineral mapping can aid in geologic mapping and fault detection and can provide a better understanding of weathering, mineralization, hydrothermal alteration, and other geologic processes. Environmental site assessment, such as mapping source areas of acid mine drainage, has resulted in the acceleration of site cleanup, saving millions of dollars and years in cleanup time. Imaging spectroscopy data and Tetracorder analysis can be used to study both terrestrial and planetary science problems. Imaging spectroscopy can be used to probe planetary systems, including their atmospheres, oceans, and land surfaces.},
	language = {en},
	number = {E12},
	urldate = {2020-09-22},
	journal = {Journal of Geophysical Research: Planets},
	author = {Clark, Roger N. and Swayze, Gregg A. and Livo, K. Eric and Kokaly, Raymond F. and Sutley, Steve J. and Dalton, J. Brad and McDougal, Robert R. and Gent, Carol A.},
	year = {2003},
	note = {\_eprint: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2002JE001847},
	keywords = {Tetracorder, expert system, imaging spectroscopy, mineral map, planetary mapping, reflectance spectroscopy}
}

@article{libran-embid_unmanned_2020,
	title = {Unmanned aerial vehicles for biodiversity-friendly agricultural landscapes - {A} systematic review},
	volume = {732},
	issn = {0048-9697},
	url = {http://www.sciencedirect.com/science/article/pii/S0048969720327212},
	doi = {10.1016/j.scitotenv.2020.139204},
	abstract = {The development of biodiversity-friendly agricultural landscapes is of major importance to meet the sustainable development challenges of our time. The emergence of unmanned aerial vehicles (UAVs), i.e. drones, has opened a new set of research and management opportunities to achieve this goal. On the one hand, this review summarizes UAV applications in agricultural landscapes, focusing on biodiversity conservation and agricultural land monitoring, based on a systematic review of the literature that resulted in 550 studies. Additionally, the review proposes how to integrate UAV research in these fields and point to new potential applications that may contribute to biodiversity-friendly agricultural landscapes. UAV-based imagery can be used to identify and monitor plants, floral resources and animals, facilitating the detection of quality habitats with high prediction power. Through vegetation indices derived from their sensors, UAVs can estimate biomass, monitor crop plant health and stress, detect pest or pathogen infestations, monitor soil fertility and target patches of high weed or invasive plant pressure, allowing precise management practices and reduced agrochemical input. Thereby, UAVs are helping to design biodiversity-friendly agricultural landscapes and to mitigate yield-biodiversity trade-offs. In conclusion, UAV applications have become a major means of biodiversity conservation and biodiversity-friendly management in agriculture, while latest developments, such as the miniaturization and decreasing costs of hyperspectral sensors, promise many new applications for the future.},
	language = {en},
	urldate = {2020-09-22},
	journal = {Science of The Total Environment},
	author = {Librán-Embid, Felipe and Klaus, Felix and Tscharntke, Teja and Grass, Ingo},
	month = aug,
	year = {2020},
	keywords = {Drones, Precision agriculture, Smart farming, UAV, Unmanned aerial systems (UAS), Vegetation monitoring, Yield-biodiversity trade-offs},
	pages = {139204}
}

@article{jiang_hyperspectral_2019,
	title = {Hyperspectral {Image} {Classification} in the {Presence} of {Noisy} {Labels}},
	volume = {57},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2018.2861992},
	abstract = {Label information plays an important role in a supervised hyperspectral image classification problem. However, current classification methods all ignore an important and inevitable problem-labels may be corrupted and collecting clean labels for training samples is difficult and often impractical. Therefore, how to learn from the database with noisy labels is a problem of great practical importance. In this paper, we study the influence of label noise on hyperspectral image classification and develop a random label propagation algorithm (RLPA) to cleanse the label noise. The key idea of RLPA is to exploit knowledge (e.g., the superpixel-based spectral-spatial constraints) from the observed hyperspectral images and apply it to the process of label propagation. Specifically, the RLPA first constructs a spectral-spatial probability transform matrix (SSPTM) that simultaneously considers the spectral similarity and superpixel-based spatial information. It then randomly chooses some training samples as “clean” samples and sets the rest as unlabeled samples, and propagates the label information from the “clean” samples to the rest unlabeled samples with the SSPTM. By repeating the random assignment (of “clean” labeled samples and unlabeled samples) and propagation, we can obtain multiple labels for each training sample. Therefore, the final propagated label can be calculated by a majority vote algorithm. Experimental studies show that the RLPA can reduce the level of noisy label and demonstrates the advantages of our proposed method over four major classifiers with a significant margin-the gains in terms of the average overall accuracy, average accuracy, and kappa are impressive, e.g., 9.18\%, 9.58\%, and 0.1043. The MATLAB source code is available at https://github.com/junjun-jiang/RLPA.},
	number = {2},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Jiang, Junjun and Ma, Jiayi and Wang, Zheng and Chen, Chen and Liu, Xianming},
	month = feb,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {Databases, Hyperspectral image classification, Hyperspectral imaging, Noise level, Noise measurement, RLPA, Radio frequency, Training, clean labeled samples, final propagated label, hyperspectral images, hyperspectral imaging, image classification, inevitable problem-labels, label information, label noise, label propagation, learning (artificial intelligence), noisy label, probability, random label propagation algorithm, spectral similarity, spectral-spatial probability, superpixel segmentation, superpixel-based spatial information, superpixel-based spectral-spatial constraints, supervised hyperspectral image classification problem, training sample, unlabeled samples},
	pages = {851--865}
}

@article{jiang_hyperspectral_2019-1,
	title = {Hyperspectral {Image} {Classification} in the {Presence} of {Noisy} {Labels}},
	volume = {57},
	issn = {0196-2892, 1558-0644},
	url = {https://ieeexplore.ieee.org/document/8476598/},
	doi = {10.1109/TGRS.2018.2861992},
	abstract = {Label information plays an important role in supervised hyperspectral image classiﬁcation problem. However, current classiﬁcation methods all ignore an important and inevitable problem—labels may be corrupted and collecting clean labels for training samples is difﬁcult, and often impractical. Therefore, how to learn from the database with noisy labels is a problem of great practical importance. In this paper, we study the inﬂuence of label noise on hyperspectral image classiﬁcation, and develop a random label propagation algorithm (RLPA) to cleanse the label noise. The key idea of RLPA is to exploit knowledge (e.g., the superpixel based spectral-spatial constraints) from the observed hyperspectral images and apply it to the process of label propagation. Speciﬁcally, RLPA ﬁrst constructs a spectralspatial probability transfer matrix (SSPTM) that simultaneously considers the spectral similarity and superpixel based spatial information. It then randomly chooses some training samples as “clean” samples and sets the rest as unlabeled samples, and propagates the label information from the “clean” samples to the rest unlabeled samples with the SSPTM. By repeating the random assignment (of “clean” labeled samples and unlabeled samples) and propagation, we can obtain multiple labels for each training sample. Therefore, the ﬁnal propagated label can be calculated by a majority vote algorithm. Experimental studies show that RLPA can reduce the level of noisy label and demonstrates the advantages of our proposed method over four major classiﬁers with a signiﬁcant margin—the gains in terms of the average OA, AA, Kappa are impressive, e.g., 9.18\%, 9.58\%, and 0.1043. The Matlab source code is available at https://github.com/junjun-jiang/RLPA.},
	language = {en},
	number = {2},
	urldate = {2020-09-14},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Jiang, Junjun and Ma, Jiayi and Wang, Zheng and Chen, Chen and Liu, Xianming},
	month = feb,
	year = {2019},
	pages = {851--865}
}

@article{jakob_need_2017,
	title = {The {Need} for {Accurate} {Geometric} and {Radiometric} {Corrections} of {Drone}-{Borne} {Hyperspectral} {Data} for {Mineral} {Exploration}: {MEPHySTo}—{A} {Toolbox} for {Pre}-{Processing} {Drone}-{Borne} {Hyperspectral} {Data}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {The {Need} for {Accurate} {Geometric} and {Radiometric} {Corrections} of {Drone}-{Borne} {Hyperspectral} {Data} for {Mineral} {Exploration}},
	url = {https://www.mdpi.com/2072-4292/9/1/88},
	doi = {10.3390/rs9010088},
	abstract = {Drone-borne hyperspectral imaging is a new and promising technique for fast and precise acquisition, as well as delivery of high-resolution hyperspectral data to a large variety of end-users. Drones can overcome the scale gap between field and air-borne remote sensing, thus providing high-resolution and multi-temporal data. They are easy to use, flexible and deliver data within cm-scale resolution. So far, however, drone-borne imagery has prominently and successfully been almost solely used in precision agriculture and photogrammetry. Drone technology currently mainly relies on structure-from-motion photogrammetry, aerial photography and agricultural monitoring. Recently, a few hyperspectral sensors became available for drones, but complex geometric and radiometric effects complicate their use for geology-related studies. Using two examples, we first show that precise corrections are required for any geological mapping. We then present a processing toolbox for frame-based hyperspectral imaging systems adapted for the complex correction of drone-borne hyperspectral imagery. The toolbox performs sensor- and platform-specific geometric distortion corrections. Furthermore, a topographic correction step is implemented to correct for rough terrain surfaces. We recommend the c-factor-algorithm for geological applications. To our knowledge, we demonstrate for the first time the applicability of the corrected dataset for lithological mapping and mineral exploration.},
	language = {en},
	number = {1},
	urldate = {2020-09-13},
	journal = {Remote Sensing},
	author = {Jakob, Sandra and Zimmermann, Robert and Gloaguen, Richard},
	month = jan,
	year = {2017},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Minas de Riotinto, UAS, UAV, drone, exploration, hyperspectral, point matching, processing, structure-from-motion},
	pages = {88}
}

@article{serranti_characterization_2018,
	title = {Characterization of microplastic litter from oceans by an innovative approach based on hyperspectral imaging},
	volume = {76},
	issn = {0956-053X},
	url = {http://www.sciencedirect.com/science/article/pii/S0956053X18301466},
	doi = {10.1016/j.wasman.2018.03.003},
	abstract = {An innovative approach, based on HyperSpectral Imaging (HSI), was developed in order to set up an efficient method to analyze marine microplastic litter. HSI was applied to samples collected by surface-trawling plankton nets from several parts of the world (i.e. Arctic, Mediterranean, South Atlantic and North Pacific). Reliable information on abundance, size, shape and polymer type for the whole ensemble of plastic particles in each sample was retrieved from single hyperspectral images. The simultaneous characterization of the polymeric composition of the plastic debris represents an important analytical advantage considering that this information, and even the validation of the plastic nature of the small debris, is a common flaw in the analysis of marine microplastic pollution. HSI was revealed as a rapid, non-invasive, non-destructive and reliable technology for the characterization of the microplastic waste, opening a promising way for improving the plastic pollution monitoring.},
	language = {en},
	urldate = {2020-09-13},
	journal = {Waste Management},
	author = {Serranti, Silvia and Palmieri, Roberta and Bonifazi, Giuseppe and Cózar, Andrés},
	month = jun,
	year = {2018},
	keywords = {Characterization, Environmental monitoring, Hyperspectral imaging, Marine microplastics, Plastic identification},
	pages = {117--125}
}

@article{davis_ocean_2002,
	title = {Ocean {PHILLS} hyperspectral imager: design, characterization, and calibration},
	volume = {10},
	copyright = {\&\#169; 2002 Optical Society of America},
	issn = {1094-4087},
	shorttitle = {Ocean {PHILLS} hyperspectral imager},
	url = {https://www.osapublishing.org/oe/abstract.cfm?uri=oe-10-4-210},
	doi = {10.1364/OE.10.000210},
	abstract = {The Ocean Portable Hyperspectral Imager for Low-Light Spectroscopy (Ocean PHILLS) is a hyperspectral imager specifically designed for imaging the coastal ocean. It uses a thinned, backside-illuminated CCD for high sensitivity and an all-reflective spectrograph with a convex grating in an Offner configuration to produce a nearly distortion-free image. The sensor, which was constructed entirely from commercially available components, has been successfully deployed during several oceanographic experiments in 1999–2001. Here we describe the instrument design and present the results of laboratory characterization and calibration. We also present examples of remote-sensing reflectance data obtained from the LEO-15 site in New Jersey that agrees well with ground-truth measurements.},
	language = {EN},
	number = {4},
	urldate = {2020-09-13},
	journal = {Optics Express},
	author = {Davis, Curtiss O. and Bowles, Jeffrey and Leathers, Robert A. and Korwan, Dan and Downes, T. Valerie and Snyder, William A. and Rhea, W. Joe and Chen, Wei and Fisher, John and Bissett, W. Paul and Reisse, Robert Alan},
	month = feb,
	year = {2002},
	note = {Publisher: Optical Society of America},
	keywords = {CCD cameras, Image quality, Imaging systems, Stray light, Systems design, Visible light},
	pages = {210--221}
}

@article{bunting_delineation_2006,
	title = {The delineation of tree crowns in {Australian} mixed species forests using hyperspectral {Compact} {Airborne} {Spectrographic} {Imager} ({CASI}) data},
	volume = {101},
	issn = {0034-4257},
	url = {http://www.sciencedirect.com/science/article/pii/S003442570500427X},
	doi = {10.1016/j.rse.2005.12.015},
	abstract = {In mixed-species forests of complex structure, the delineation of tree crowns is problematic because of their varying dimensions and reflectance characteristics, the existence of several layers of canopy (including understorey), and shadowing within and between crowns. To overcome this problem, an algorithm for delineating tree crowns has been developed using eCognition Expert and hyperspectral Compact Airborne Spectrographic Imager (CASI-2) data acquired over a forested landscape near Injune, central east Queensland, Australia. The algorithm has six components: 1) the differentiation of forest, non-forest and understorey; 2) initial segmentation of the forest area and allocation of segments (objects) to larger objects associated with forest spectral types (FSTs); 3) initial identification of object maxima as seeds within these larger objects and their expansion to the edges of crowns or clusters of crowns; 4) subsequent classification-based separation of the resulting objects into crown or cluster classes; 5) further iterative splitting of the cluster classes to delineate more crowns; and 6) identification and subsequent merging of oversplit objects into crowns or clusters. In forests with a high density of individuals (e.g., regrowth), objects associated with tree clusters rather than crowns are delineated and local maxima counted to approximate density. With reference to field data, the delineation process provided accuracies {\textgreater}∼70\% (range 48–88\%) for individuals or clusters of trees of the same species with diameter at breast height (DBH) exceeding 10 cm (senescent and dead trees excluded), with lower accuracies associated with dense stands containing several canopy layers, as many trees were obscured from the view of the CASI sensor. Although developed using 1-m spatial resolution CASI data acquired over Australian forests, the algorithm has application elsewhere and is currently being considered for integration into the Definiens product portfolio for use by the wider community.},
	language = {en},
	number = {2},
	urldate = {2020-09-13},
	journal = {Remote Sensing of Environment},
	author = {Bunting, Peter and Lucas, Richard},
	month = mar,
	year = {2006},
	keywords = {Australia, CASI, Classification, Crown delineation, Forests, Hyperspectral, Image segmentation, Queensland, eCognition},
	pages = {230--248}
}

@inproceedings{teke_short_2013,
	title = {A short survey of hyperspectral remote sensing applications in agriculture},
	doi = {10.1109/RAST.2013.6581194},
	abstract = {Hyperspectral sensors are devices that acquire images over hundreds of spectral bands, thereby enabling the extraction of spectral signatures for objects or materials observed. Hyperspectral remote sensing has been used over a wide range of applications, such as agriculture, forestry, geology, ecological monitoring and disaster monitoring. In this paper, the specific application of hyperspectral remote sensing to agriculture is examined. The technological development of agricultural methods is of critical importance as the world's population is anticipated to continuously rise much beyond the current number of 7 billion. One area upon which hyperspectral sensing can yield considerable impact is that of precision agriculture - the use of observations to optimize the use of resources and management of farming practices. For example, hyperspectral image processing is used in the monitoring of plant diseases, insect pests and invasive plant species; the estimation of crop yield; and the fine classification of crop distributions. This paper also presents a detailed overview of hyperspectral data processing techniques and suggestions for advancing the agricultural applications of hyperspectral technologies in Turkey.},
	booktitle = {2013 6th {International} {Conference} on {Recent} {Advances} in {Space} {Technologies} ({RAST})},
	author = {Teke, Mustafa and Deveci, Hüsne Seda and Haliloğlu, Onur and Gürbüz, Sevgi Zübeyde and Sakarya, Ufuk},
	month = jun,
	year = {2013},
	keywords = {Agriculture, Hyperspectral imaging, Monitoring, Satellites, Sensors, Turkey, agriculture, crop yield, disaster monitoring, ecological monitoring, farming practice management, feature extraction, forestry, geology, geophysical image processing, hyperspectral data processing techniques, hyperspectral image processing, hyperspectral imaging, hyperspectral remote sensing applications, hyperspectral sensors, image acquisition, image classification, image sensors, insect pests, invasive plant species, plant diseases, precision agriculture, remote sensing, spectral bands, spectral signature extraction, survey, vegetation mapping, world population},
	pages = {171--176}
}

@article{signoroni_deep_2019,
	title = {Deep {Learning} {Meets} {Hyperspectral} {Image} {Analysis}: {A} {Multidisciplinary} {Review}},
	volume = {5},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Deep {Learning} {Meets} {Hyperspectral} {Image} {Analysis}},
	url = {https://www.mdpi.com/2313-433X/5/5/52},
	doi = {10.3390/jimaging5050052},
	abstract = {Modern hyperspectral imaging systems produce huge datasets potentially conveying a great abundance of information; such a resource, however, poses many challenges in the analysis and interpretation of these data. Deep learning approaches certainly offer a great variety of opportunities for solving classical imaging tasks and also for approaching new stimulating problems in the spatial\&ndash;spectral domain. This is fundamental in the driving sector of Remote Sensing where hyperspectral technology was born and has mostly developed, but it is perhaps even more true in the multitude of current and evolving application sectors that involve these imaging technologies. The present review develops on two fronts: on the one hand, it is aimed at domain professionals who want to have an updated overview on how hyperspectral acquisition techniques can combine with deep learning architectures to solve specific tasks in different application fields. On the other hand, we want to target the machine learning and computer vision experts by giving them a picture of how deep learning technologies are applied to hyperspectral data from a multidisciplinary perspective. The presence of these two viewpoints and the inclusion of application fields other than Remote Sensing are the original contributions of this review, which also highlights some potentialities and critical issues related to the observed development trends.},
	language = {en},
	number = {5},
	urldate = {2020-09-13},
	journal = {Journal of Imaging},
	author = {Signoroni, Alberto and Savardi, Mattia and Baronio, Annalisa and Benini, Sergio},
	month = may,
	year = {2019},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {deep learning, hyperspectral imaging, image processing, machine learning, neural networks},
	pages = {52}
}

@article{misra_self-supervised_2019,
	title = {Self-{Supervised} {Learning} of {Pretext}-{Invariant} {Representations}},
	url = {http://arxiv.org/abs/1912.01991},
	abstract = {The goal of self-supervised learning from images is to construct image representations that are semantically meaningful via pretext tasks that do not require semantic annotations for a large training set of images. Many pretext tasks lead to representations that are covariant with image transformations. We argue that, instead, semantic representations ought to be invariant under such transformations. Specifically, we develop Pretext-Invariant Representation Learning (PIRL, pronounced as "pearl") that learns invariant representations based on pretext tasks. We use PIRL with a commonly used pretext task that involves solving jigsaw puzzles. We find that PIRL substantially improves the semantic quality of the learned image representations. Our approach sets a new state-of-the-art in self-supervised learning from images on several popular benchmarks for self-supervised learning. Despite being unsupervised, PIRL outperforms supervised pre-training in learning image representations for object detection. Altogether, our results demonstrate the potential of self-supervised learning of image representations with good invariance properties.},
	urldate = {2020-09-04},
	journal = {arXiv:1912.01991 [cs]},
	author = {Misra, Ishan and van der Maaten, Laurens},
	month = dec,
	year = {2019},
	note = {arXiv: 1912.01991},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning}
}

@article{he_momentum_2020,
	title = {Momentum {Contrast} for {Unsupervised} {Visual} {Representation} {Learning}},
	url = {http://arxiv.org/abs/1911.05722},
	abstract = {We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by MoCo transfer well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins. This suggests that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks.},
	urldate = {2020-09-04},
	journal = {arXiv:1911.05722 [cs]},
	author = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
	month = mar,
	year = {2020},
	note = {arXiv: 1911.05722},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{xu_self-supervised_2019,
	title = {Self-supervised {Domain} {Adaptation} for {Computer} {Vision} {Tasks}},
	volume = {7},
	issn = {2169-3536},
	url = {http://arxiv.org/abs/1907.10915},
	doi = {10.1109/ACCESS.2019.2949697},
	abstract = {Recent progress of self-supervised visual representation learning has achieved remarkable success on many challenging computer vision benchmarks. However, whether these techniques can be used for domain adaptation has not been explored. In this work, we propose a generic method for self-supervised domain adaptation, using object recognition and semantic segmentation of urban scenes as use cases. Focusing on simple pretext/auxiliary tasks (e.g. image rotation prediction), we assess different learning strategies to improve domain adaptation effectiveness by self-supervision. Additionally, we propose two complementary strategies to further boost the domain adaptation accuracy on semantic segmentation within our method, consisting of prediction layer alignment and batch normalization calibration. The experimental results show adaptation levels comparable to most studied domain adaptation methods, thus, bringing self-supervision as a new alternative for reaching domain adaptation. The code is available at https://github.com/Jiaolong/self-supervised-da.},
	urldate = {2020-08-29},
	journal = {IEEE Access},
	author = {Xu, Jiaolong and Xiao, Liang and Lopez, Antonio M.},
	year = {2019},
	note = {arXiv: 1907.10915},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	pages = {156694--156706}
}

@article{howard_universal_2018,
	title = {Universal {Language} {Model} {Fine}-tuning for {Text} {Classification}},
	url = {http://arxiv.org/abs/1801.06146},
	abstract = {Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24\% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.},
	urldate = {2020-08-29},
	journal = {arXiv:1801.06146 [cs, stat]},
	author = {Howard, Jeremy and Ruder, Sebastian},
	month = may,
	year = {2018},
	note = {arXiv: 1801.06146},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{vermote_second_1997,
	title = {Second {Simulation} of the {Satellite} {Signal} in the {Solar} {Spectrum}, {6S}: an overview},
	volume = {35},
	issn = {1558-0644},
	shorttitle = {Second {Simulation} of the {Satellite} {Signal} in the {Solar} {Spectrum}, {6S}},
	doi = {10.1109/36.581987},
	abstract = {Remote sensing from satellite or airborne platforms of land or sea surfaces in the visible and near infrared is strongly affected by the presence of the atmosphere along the path from Sun to target (surface) to sensor. This paper presents 6S (Second Simulation of the Satellite Signal in the Solar Spectrum), a computer code which can accurately simulate the above problems. The 6S code is an improved version of 5S (Simulation of the Satellite Signal in the Solar Spectrum), developed by the Laboratoire d'Optique Atmospherique ten years ago. The new version now permits calculations of near-nadir (down-looking) aircraft observations, accounting for target elevation, non lambertian surface conditions, and new absorbing species (CH/sub 4/, N/sub 2/O, CO). The computational accuracy for Rayleigh and aerosol scattering effects has been improved by the use of state-of-the-art approximations and implementation of the successive order of scattering (SOS) algorithm. The step size (resolution) used for spectral integration has been improved to 2.5 nm. The goal of this paper is not to provide a complete description of the methods used as that information is detailed in the 6S manual, but rather to illustrate the impact of the improvements between 5S and 6S by examining some typical remote sensing situations. Nevertheless, the 6S code has still limitations. It cannot handle spherical atmosphere and as a result, it cannot be used for limb observations. In addition, the decoupling the authors are using for absorption and scattering effects does not allow to use the code in presence of strong absorption bands.},
	number = {3},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Vermote, E.F. and Tanre, D. and Deuze, J.L. and Herman, M. and Morcette, J.-J.},
	month = may,
	year = {1997},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {6S, Atmosphere, Atmospheric modeling, Computational modeling, Computer simulation, Infrared sensors, Land surface, Rayleigh scattering, Remote sensing, Satellites, Sea surface, Second Simulation of the Satellite Signal in the Solar Spectrum, aerosol scattering, airborne remote sensing, atmosphere optics, atmospheric optics, computer code, geophysical measurement technique, geophysical techniques, land surface, light propagation, model, near infrared, near-nadir, nonlambertian surface conditions, ocean, oceanographic techniques, optical imaging, remote sensing, satellite remote sensing, sea surface, successive order of scattering, target elevation, terrain mapping, visible region},
	pages = {675--686}
}

@article{schaepman-strub_reflectance_2006,
	title = {Reflectance quantities in optical remote sensing—definitions and case studies},
	volume = {103},
	issn = {0034-4257},
	url = {http://www.sciencedirect.com/science/article/pii/S0034425706001167},
	doi = {10.1016/j.rse.2006.03.002},
	abstract = {The remote sensing community puts major efforts into calibration and validation of sensors, measurements, and derived products to quantify and reduce uncertainties. Given recent advances in instrument design, radiometric calibration, atmospheric correction, algorithm development, product development, validation, and delivery, the lack of standardization of reflectance terminology and products becomes a considerable source of error. This article provides full access to the basic concept and definitions of reflectance quantities, as given by Nicodemus et al. [Nicodemus, F.E., Richmond, J.C., Hsia, J.J., Ginsberg, I.W., and Limperis, T. (1977). Geometrical Considerations and Nomenclature for Reflectance. In: National Bureau of Standards, US Department of Commerce, Washington, D.C. URL: http://physics.nist.gov/Divisions/Div844/facilities/specphoto/pdf/geoConsid.pdf.] and Martonchik et al. [Martonchik, J.V., Bruegge, C.J., and Strahler, A. (2000). A review of reflectance nomenclature used in remote sensing. Remote Sensing Reviews, 19, 9–20.]. Reflectance terms such as BRDF, HDRF, BRF, BHR, DHR, black-sky albedo, white-sky albedo, and blue-sky albedo are defined, explained, and exemplified, while separating conceptual from measurable quantities. We use selected examples from the peer-reviewed literature to demonstrate that very often the current use of reflectance terminology does not fulfill physical standards and can lead to systematic errors. Secondly, the paper highlights the importance of a proper usage of definitions through quantitative comparison of different reflectance products with special emphasis on wavelength dependent effects. Reflectance quantities acquired under hemispherical illumination conditions (i.e., all outdoor measurements) depend not only on the scattering properties of the observed surface, but as well on atmospheric conditions, the object's surroundings, and the topography, with distinct expression of these effects in different wavelengths. We exemplify differences between the hemispherical and directional illumination quantities, based on observations (i.e., MISR), and on reflectance simulations of natural surfaces (i.e., vegetation canopy and snow cover). In order to improve the current situation of frequent ambiguous usage of reflectance terms and quantities, we suggest standardizing the terminology in reflectance product descriptions and that the community carefully utilizes the proposed reflectance terminology in scientific publications.},
	language = {en},
	number = {1},
	urldate = {2020-08-29},
	journal = {Remote Sensing of Environment},
	author = {Schaepman-Strub, G. and Schaepman, M. E. and Painter, T. H. and Dangel, S. and Martonchik, J. V.},
	month = jul,
	year = {2006},
	keywords = {BRDF, Definition, Nomenclature, Reflectance, Snow, Spectrodirectional, Terminology, Vegetation},
	pages = {27--42}
}

@article{kotchenova_radiative_2008,
	title = {Radiative transfer codes for atmospheric correction and aerosol retrieval: intercomparison study},
	volume = {47},
	copyright = {\&\#169; 2008 Optical Society of America},
	issn = {2155-3165},
	shorttitle = {Radiative transfer codes for atmospheric correction and aerosol retrieval},
	url = {https://www.osapublishing.org/ao/abstract.cfm?uri=ao-47-13-2215},
	doi = {10.1364/AO.47.002215},
	abstract = {Results are summarized for a scientific project devoted to the comparison of four atmospheric radiative transfer codes incorporated into different satellite data processing algorithms, namely, 6SV1.1 (second simulation of a satellite signal in the solar spectrum, vector, version 1.1), RT3 (radiative transfer), MODTRAN (moderate resolution atmospheric transmittance and radiance code), and SHARM (spherical harmonics). The performance of the codes is tested against well-known benchmarks, such as Coulson's tabulated values and a Monte Carlo code. The influence of revealed differences on aerosol optical thickness and surface reflectance retrieval is estimated theoretically by using a simple mathematical approach. All information about the project can be found at http://rtcodes.ltdri.org.},
	language = {EN},
	number = {13},
	urldate = {2020-08-29},
	journal = {Applied Optics},
	author = {Kotchenova, Svetlana Y. and Vermote, Eric F. and Levy, Robert and Lyapustin, Alexei},
	month = may,
	year = {2008},
	note = {Publisher: Optical Society of America},
	keywords = {Atmospheric correction, Atmospheric transmittance, Mie theory, Passive remote sensing, Radiative transfer, Remote sensing},
	pages = {2215--2226}
}

@article{tarabalka_segmentation_2010,
	title = {Segmentation and classification of hyperspectral images using watershed transformation},
	volume = {43},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S003132031000049X},
	doi = {10.1016/j.patcog.2010.01.016},
	abstract = {Hyperspectral imaging, which records a detailed spectrum of light for each pixel, provides an invaluable source of information regarding the physical nature of the different materials, leading to the potential of a more accurate classification. However, high dimensionality of hyperspectral data, usually coupled with limited reference data available, limits the performances of supervised classification techniques. The commonly used pixel-wise classification lacks information about spatial structures of the image. In order to increase classification performances, integration of spatial information into the classification process is needed. In this paper, we propose to extend the watershed segmentation algorithm for hyperspectral images, in order to define information about spatial structures. In particular, several approaches to compute a one-band gradient function from hyperspectral images are proposed and investigated. The accuracy of the watershed algorithms is demonstrated by the further incorporation of the segmentation maps into a classifier. A new spectral–spatial classification scheme for hyperspectral images is proposed, based on the pixel-wise Support Vector Machines classification, followed by majority voting within the watershed regions. Experimental segmentation and classification results are presented on two hyperspectral images. It is shown in experiments that when the number of spectral bands increases, the feature extraction and the use of multidimensional gradients appear to be preferable to the use of vectorial gradients. The integration of the spatial information from the watershed segmentation in the hyperspectral image classifier improves the classification accuracies and provides classification maps with more homogeneous regions, compared to pixel-wise classification and previously proposed spectral–spatial classification techniques. The developed method is especially suitable for classifying images with large spatial structures.},
	language = {en},
	number = {7},
	urldate = {2020-08-29},
	journal = {Pattern Recognition},
	author = {Tarabalka, Y. and Chanussot, J. and Benediktsson, J. A.},
	month = jul,
	year = {2010},
	keywords = {Classification, Hyperspectral images, Mathematical morphology, Segmentation, Watershed},
	pages = {2367--2379}
}

@inproceedings{torralba_unbiased_2011,
	title = {Unbiased look at dataset bias},
	doi = {10.1109/CVPR.2011.5995347},
	abstract = {Datasets are an integral part of contemporary object recognition research. They have been the chief reason for the considerable progress in the field, not just as source of large amounts of training data, but also as means of measuring and comparing performance of competing algorithms. At the same time, datasets have often been blamed for narrowing the focus of object recognition research, reducing it to a single benchmark performance number. Indeed, some datasets, that started out as data capture efforts aimed at representing the visual world, have become closed worlds unto themselves (e.g. the Corel world, the Caltech-101 world, the PASCAL VOC world). With the focus on beating the latest benchmark numbers on the latest dataset, have we perhaps lost sight of the original purpose? The goal of this paper is to take stock of the current state of recognition datasets. We present a comparison study using a set of popular datasets, evaluated based on a number of criteria including: relative data bias, cross-dataset generalization, effects of closed-world assumption, and sample value. The experimental results, some rather surprising, suggest directions that can improve dataset collection as well as algorithm evaluation protocols. But more broadly, the hope is to stimulate discussion in the community regarding this very important, but largely neglected issue.},
	booktitle = {{CVPR} 2011},
	author = {Torralba, Antonio and Efros, Alexei A.},
	month = jun,
	year = {2011},
	note = {ISSN: 1063-6919},
	keywords = {Communities, Internet, Object recognition, Support vector machines, Testing, Training, Visualization, algorithm evaluation protocols, closed world assumption effects, contemporary object recognition, cross dataset generalization, data capture, object recognition, recognition datasets, relative data bias, sample value, visual databases},
	pages = {1521--1528}
}

@article{gebru_datasheets_2020,
	title = {Datasheets for {Datasets}},
	url = {http://arxiv.org/abs/1803.09010},
	abstract = {The machine learning community currently has no standardized process for documenting datasets, which can lead to severe consequences in high-stakes domains. To address this gap, we propose datasheets for datasets. In the electronics industry, every component, no matter how simple or complex, is accompanied with a datasheet that describes its operating characteristics, test results, recommended uses, and other information. By analogy, we propose that every dataset be accompanied with a datasheet that documents its motivation, composition, collection process, recommended uses, and so on. Datasheets for datasets will facilitate better communication between dataset creators and dataset consumers, and encourage the machine learning community to prioritize transparency and accountability.},
	urldate = {2020-08-28},
	journal = {arXiv:1803.09010 [cs]},
	author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Daumé III, Hal and Crawford, Kate},
	month = mar,
	year = {2020},
	note = {arXiv: 1803.09010},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Databases, Computer Science - Machine Learning}
}

@article{livens_spatio-spectral_2017,
	title = {A {SPATIO}-{SPECTRAL} {CAMERA} {FOR} {HIGH} {RESOLUTION} {HYPERSPECTRAL} {IMAGING}},
	volume = {XLII-2/W6},
	issn = {2194-9034},
	url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2-W6/223/2017/},
	doi = {10.5194/isprs-archives-XLII-2-W6-223-2017},
	abstract = {Imaging with a conventional frame camera from a moving remotely piloted aircraft system (RPAS) is by design very inefficient. Less than 1\% of the flying time is used for collecting light. This unused potential can be utilized by an innovative imaging concept, the spatio-spectral camera. The core of the camera is a frame sensor with a large number of hyperspectral filters arranged on the sensor in stepwise lines. It combines the advantages of frame cameras with those of pushbroom cameras. By acquiring images in rapid succession, such a camera can collect detailed hyperspectral information, while retaining the high spatial resolution offered by the sensor.},
	language = {en},
	urldate = {2020-08-25},
	journal = {ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Livens, S. and Pauly, K. and Baeck, P. and Blommaert, J. and Nuyts, D. and Zender, J. and Delauré, B.},
	month = aug,
	year = {2017},
	pages = {223--228}
}

@article{adao_hyperspectral_2017,
	title = {Hyperspectral {Imaging}: {A} {Review} on {UAV}-{Based} {Sensors}, {Data} {Processing} and {Applications} for {Agriculture} and {Forestry}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Hyperspectral {Imaging}},
	url = {https://www.mdpi.com/2072-4292/9/11/1110},
	doi = {10.3390/rs9111110},
	abstract = {Traditional imagery—provided, for example, by RGB and/or NIR sensors—has proven to be useful in many agroforestry applications. However, it lacks the spectral range and precision to profile materials and organisms that only hyperspectral sensors can provide. This kind of high-resolution spectroscopy was firstly used in satellites and later in manned aircraft, which are significantly expensive platforms and extremely restrictive due to availability limitations and/or complex logistics. More recently, UAS have emerged as a very popular and cost-effective remote sensing technology, composed of aerial platforms capable of carrying small-sized and lightweight sensors. Meanwhile, hyperspectral technology developments have been consistently resulting in smaller and lighter sensors that can currently be integrated in UAS for either scientific or commercial purposes. The hyperspectral sensors’ ability for measuring hundreds of bands raises complexity when considering the sheer quantity of acquired data, whose usefulness depends on both calibration and corrective tasks occurring in pre- and post-flight stages. Further steps regarding hyperspectral data processing must be performed towards the retrieval of relevant information, which provides the true benefits for assertive interventions in agricultural crops and forested areas. Considering the aforementioned topics and the goal of providing a global view focused on hyperspectral-based remote sensing supported by UAV platforms, a survey including hyperspectral sensors, inherent data processing and applications focusing both on agriculture and forestry—wherein the combination of UAV and hyperspectral sensors plays a center role—is presented in this paper. Firstly, the advantages of hyperspectral data over RGB imagery and multispectral data are highlighted. Then, hyperspectral acquisition devices are addressed, including sensor types, acquisition modes and UAV-compatible sensors that can be used for both research and commercial purposes. Pre-flight operations and post-flight pre-processing are pointed out as necessary to ensure the usefulness of hyperspectral data for further processing towards the retrieval of conclusive information. With the goal of simplifying hyperspectral data processing—by isolating the common user from the processes’ mathematical complexity—several available toolboxes that allow a direct access to level-one hyperspectral data are presented. Moreover, research works focusing the symbiosis between UAV-hyperspectral for agriculture and forestry applications are reviewed, just before the paper’s conclusions.},
	language = {en},
	number = {11},
	urldate = {2020-08-16},
	journal = {Remote Sensing},
	author = {Adão, Telmo and Hruška, Jonáš and Pádua, Luís and Bessa, José and Peres, Emanuel and Morais, Raul and Sousa, Joaquim João},
	month = nov,
	year = {2017},
	note = {Number: 11
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {UAS, UAV, agriculture, agroforestry, forestry, hyperspectral, hyperspectral data processing, hyperspectral sensors},
	pages = {1110}
}

@article{thenkabail_hyperspectral_2000,
	title = {Hyperspectral {Vegetation} {Indices} and {Their} {Relationships} with {Agricultural} {Crop} {Characteristics}},
	volume = {71},
	issn = {0034-4257},
	url = {http://www.sciencedirect.com/science/article/pii/S003442579900067X},
	doi = {10.1016/S0034-4257(99)00067-X},
	abstract = {The objective of this paper is to determine spectral bands that are best suited for characterizing agricultural crop biophysical variables. The data for this study comes from ground-level hyperspectral reflectance measurements of cotton, potato, soybeans, corn, and sunflower. Reflectance was measured in 490 discrete narrow bands between 350 and 1,050 nm. Observed crop characteristics included wet biomass, leaf area index, plant height, and (for cotton only) yield. Three types of hyperspectral predictors were tested: optimum multiple narrow band reflectance (OMNBR), narrow band normalized difference vegetation index (NDVI) involving all possible two-band combinations of 490 channels, and the soil-adjusted vegetation indices. A critical problem with OMNBR models was that of “over fitting” (i.e., using more spectral channels than experimental samples to obtain a highly maximum R2 value). This problem was addressed by comparing the R2 values of crop variables with the R2 values computed for random data of a large sample size. The combinations of two to four narrow bands in OMNBR models explained most (64\% to 92\%) of the variability in crop biophysical variables. The second part of the paper describes a rigorous search procedure to identify the best narrow band NDVI predictors of crop biophysical variables. Special narrow band lambda (λ1) versus lambda (λ2) plots of R2 values illustrate the most effective wavelength combinations (λ1 and λ2) and bandwidths (Δλ1 and Δλ2) for predicting the biophysical quantities of each crop. The best of these two-band indices were further tested to see if soil adjustment or nonlinear fitting could improve their predictive accuracy. The best of the narrow band NDVI models explained 64\% to 88\% variability in different crop biophysical variables. A strong relationship with crop characteristics is located in specific narrow bands in the longer wavelength portion of the red (650 nm to 700 nm), with secondary clusters in the shorter wavelength portion of green (500 nm to 550 nm), in one particular section of the near-infrared (900 nm to 940 nm), and in the moisture sensitive near-infrared (centered at 982 nm). This study recommends a 12 narrow band sensor, in the 350 nm to 1,050 nm range of the spectrum, for optimum estimation of agricultural crop biophysical information.},
	language = {en},
	number = {2},
	urldate = {2020-08-16},
	journal = {Remote Sensing of Environment},
	author = {Thenkabail, Prasad S and Smith, Ronald B and De Pauw, Eddy},
	month = feb,
	year = {2000},
	pages = {158--182}
}

@article{khan_hytexila_2018,
	title = {{HyTexiLa}: {High} {Resolution} {Visible} and {Near} {Infrared} {Hyperspectral} {Texture} {Images}},
	volume = {18},
	issn = {1424-8220},
	shorttitle = {{HyTexiLa}},
	url = {http://www.mdpi.com/1424-8220/18/7/2045},
	doi = {10.3390/s18072045},
	abstract = {We present a dataset of close range hyperspectral images of materials that span the visible and near infrared spectrums: HyTexiLa (Hyperspectral Texture images acquired in Laboratory). The data is intended to provide high spectral and spatial resolution reﬂectance images of 112 materials to study spatial and spectral textures. In this paper we discuss the calibration of the data and the method for addressing the distortions during image acquisition. We provide a spectral analysis based on non-negative matrix factorization to quantify the spectral complexity of the samples and extend local binary pattern operators to the hyperspectral texture analysis. The results demonstrate that although the spectral complexity of each of the textures is generally low, increasing the number of bands permits better texture classiﬁcation, with the opponent band local binary pattern feature giving the best performance.},
	language = {en},
	number = {7},
	urldate = {2020-08-15},
	journal = {Sensors},
	author = {Khan, Haris and Mihoubi, Sofiane and Mathon, Benjamin and Thomas, Jean-Baptiste and Hardeberg, Jon},
	month = jun,
	year = {2018},
	pages = {2045}
}

@article{chen_experimental_2018,
	title = {Experimental {Demonstration} of {Remote} and {Compact} {Imaging} {Spectrometer} {Based} on {Mobile} {Devices}},
	volume = {18},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/18/7/1989},
	doi = {10.3390/s18071989},
	abstract = {Imaging spectrometers show great potential for environmental and biomedical sensing applications. Selﬁe sticks, which are tools used to take photographs or videos, have gained global popularity in recent years. Few people have connected these two objects, and few people have researched the application of imaging spectrometers to perform scientiﬁc monitoring in point-of-use scenarios. In this paper, we develop a compact imaging spectrometer (35 g in weight, 18 mm in diameter, and 72 mm in length) that can be equipped on a motorized selﬁe stick to perform remote sensing. We applied this system to perform environmental and facial remote sensing via motorized scanning. The absorption of chlorophyll and hemoglobin can be found in the reﬂectance spectra, indicating that our system can be used in urban greening monitoring and point-of-care testing. In addition, this compact imaging spectrometer was also easily attached to an underwater dome port and a quad-rotor unmanned aerial vehicle to perform underwater and airborne spectral detection. Our system offers a route toward mobile imaging spectrometers used in daily life.},
	language = {en},
	number = {7},
	urldate = {2020-08-15},
	journal = {Sensors},
	author = {Chen, Jie and Cai, Fuhong and He, Rongxiao and He, Sailing},
	month = jun,
	year = {2018},
	pages = {1989}
}

@inproceedings{dwight_compact_2018,
	title = {Compact snapshot image mapping spectrometer ({SNAP}-{IMS}) for hyperspectral data cube acquisition using unmanned aerial vehicle ({UAV}) environmental imaging},
	volume = {10657},
	url = {https://www-spiedigitallibrary-org.ezproxy1.library.usyd.edu.au/conference-proceedings-of-spie/10657/106570G/Compact-snapshot-image-mapping-spectrometer-SNAP-IMS-for-hyperspectral-data/10.1117/12.2305117.short},
	doi = {10.1117/12.2305117},
	abstract = {Due to the growth of miniature unmanned aerial vehicles (UAVs) and small spacecraft (SmallSats) in recent years, there has been a push for the development of miniaturized spectral imagers to be incorporated with them. An efficient, compact hyperspectral imager integrated with these vehicles provides a cost-effective platform for environmental sensing applications that include the monitoring of agriculture, vegetation, geology, and pollutants. We present here the development and integration of a hyperspectral imaging system called the SNAP-IMS, originally used for biomedical detection, with an Octocopter UAV. The entire collected hyperspectral data cube is 350x400x55 (x,y,\&lambda;) spatial/spectral samples. The final system enclosure (288 mm x 150 mm x 160 mm) weighs 3.6 kg (7.9 lbs), offering minimal size and weight. The payload’s power consumption is marginal as there are no mechanical scanning components; the existing power requirements are dedicated exclusively to CCD frame acquisition. Experimental testing included several flights on board the Octocopter UAV, acquiring hyperspectral data cubes at 1/100 second. Snapshot mode and short integration times mitigate motion artifacts. The low size, weight, and power consumption can offer longer and higher flights at smaller drone sizes. These improvements augment the potential for additional instrument incorporation (i.e. LiDAR, Multi-spectral IR) in the future. Imaging results and system description are presented and discussed.},
	urldate = {2020-08-15},
	booktitle = {Next-{Generation} {Spectroscopic} {Technologies} {XI}},
	publisher = {International Society for Optics and Photonics},
	author = {Dwight, Jason G. and Tkaczyk, Tomasz S. and Alexander, David and Pawlowski, Michal E. and Luvall, Jeffrey C. and Tatum, Paul F. and Jedlovec, Gary J.},
	month = may,
	year = {2018},
	pages = {106570G}
}

@article{fjeldtvedt_efficient_2018,
	title = {An {Efficient} {Real}-{Time} {FPGA} {Implementation} of the {CCSDS}-123 {Compression} {Standard} for {Hyperspectral} {Images}},
	volume = {11},
	issn = {2151-1535},
	doi = {10.1109/JSTARS.2018.2869697},
	abstract = {Hyperspectral imaging (HSI) can extract information from scenes on the earth surface acquired by airborne or spaceborne sensors. On-board processing of HSI is characterized by large datasets on one side and limited processing time and communication links on the other. The CCSDS-123 algorithm is a compression standard assembled for space-related application that allows compacted data transmission via a transmission link. In this paper, a low-complexity high-throughput field-programmable gate array (FPGA) implementation of CCSDS-123 compression algorithm with band interleaved by pixel ordering is presented. Hardware accelerators implemented in FPGAs are increasingly used for custom tasks due to their efficiency, low power, and reconfigurability. The proposed implementation of CCSDS-123 compression standard has been tested on ZedBoard development board containing a Zynq-7020 FPGA. The results are verified against an existing software implementation. The synthesized design can perform on-the-fly processing of hyperspectral images with maximum operating frequency of 147 MHz. The achieved throughput of 147 Msamples/s (2.35 Gb/s) is higher when compared with the throughput reported in recent state-of-the-art FPGA implementations.},
	number = {10},
	journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	author = {Fjeldtvedt, Johan and Orlandić, Milica and Johansen, Tor Arne},
	month = oct,
	year = {2018},
	note = {Conference Name: IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	keywords = {CCSDS-123 compression, Entropy, FPGA implementations, Field programmable gate arrays, HSI, Hyperspectral imaging, Image coding, On-board processing, Real-time systems, Standards, Throughput, ZedBoard development board, airborne sensors, communication links, compression algorithm, data compression, data transmission, field programmable gate arrays, field-programmable gate arrays (FPGAs), geophysical image processing, hardware accelerators, high-throughput field-programmable gate array implementation, hyperspectral imaging, hyperspectral imaging (HSI), information extraction, information retrieval, limited processing time, lossless compression, on-the-fly processing, software implementation, space-related application, space-related applications, spaceborne sensors, transmission link},
	pages = {3841--3852}
}

@article{cai_design_2018,
	title = {The design and implementation of a low-cost multispectral endoscopy through galvo scanning of a fiber bundle},
	volume = {428},
	issn = {0030-4018},
	url = {http://www.sciencedirect.com/science/article/pii/S0030401818306369},
	doi = {10.1016/j.optcom.2018.07.044},
	abstract = {In this work, we report the design and implementation of a compact, cost-effective multispectral imaging endoscope. First, a spectral image scanning system is built, by combining a micro-imaging system with a spectrometer and a galvo mirror. Then a fiber bundle is utilized to transmit the optical image of a sample to the spectral image scanning system. Through galvo scanning, a 3D spectral image cube emitted from the sample can be acquired. Thus, a spectral image scanning endoscope is achieved, by combining such a scanning spectral imaging system with the fiber bundle. This obtained spectral image scanning endoscope is low-cost and easy to fabricate. The spectral imaging endoscope can be applied to perform macro-imaging for biological samples and micro-imaging for resolution test target. From those tests, the spectral resolution of our imaging system is about 5 nm and the spatial resolution is about 26 μm. These results suggest that our system has the potential for clinical and point-of-care applications.},
	language = {en},
	urldate = {2020-08-15},
	journal = {Optics Communications},
	author = {Cai, Fuhong and Wang, Yalun and Gao, Min and He, Sailing},
	month = dec,
	year = {2018},
	keywords = {Endoscope, Galvo mirror, Image relay, Imaging, Spectral imaging},
	pages = {1--6}
}

@article{dwight_compact_2018-1,
	title = {Compact snapshot image mapping spectrometer for unmanned aerial vehicle hyperspectral imaging},
	volume = {12},
	issn = {1931-3195, 1931-3195},
	url = {https://www-spiedigitallibrary-org.ezproxy1.library.usyd.edu.au/journals/Journal-of-Applied-Remote-Sensing/volume-12/issue-4/044004/Compact-snapshot-image-mapping-spectrometer-for-unmanned-aerial-vehicle-hyperspectral/10.1117/1.JRS.12.044004.short},
	doi = {10.1117/1.JRS.12.044004},
	abstract = {Due to the surge in the development of unmanned aerial vehicles (UAVs) and small spacecraft (CubeSats and SmallSats) in recent years, there has been a push to develop miniaturized instrumentation to be incorporated on such platforms. A compact hyperspectral imager integrated with these vehicles provides a cost-effective platform for a range of environmental sensing applications that include the monitoring of vegetation, urban development, and lightning. We present the snapshot hyperspectral imaging system (SNAP-IMS), requiring no scanning and capable of integration with a UAV. The collected hyperspectral data cube is 350 × 400 × 55 (x , y , λ) and is acquired within a single camera exposure. The system (288 mm × 150 mm × 160 mm) weighs 3.6 kg (7.9 lb), and its power consumption is marginal as there are no scanning components. Experimental testing included several flights over an area covered by diverse types of vegetation and man-made structures. Data cubes are recorded at a 1/100 s integration time, which mitigated motion-related artifacts. The low size, mass, and power consumption of the imager can enable longer and higher flights at smaller drone sizes and allow easy, portable spectral imaging. Imaging results and the system description are presented and discussed.},
	number = {4},
	urldate = {2020-08-15},
	journal = {Journal of Applied Remote Sensing},
	author = {Dwight, Jason G. and Tkaczyk, Tomasz S. and Alexander, David and Pawlowski, Michal E. and Stoian, Razvan-Ionut and Luvall, Jeffery C. and Tatum, Paul F. and Jedlovec, Gary J.},
	month = dec,
	year = {2018},
	note = {Publisher: International Society for Optics and Photonics},
	pages = {044004}
}

@inproceedings{bakken_effect_2019,
	title = {The effect of dimensionality reduction on signature-based target detection for hyperspectral remote sensing},
	volume = {11131},
	url = {https://www-spiedigitallibrary-org.ezproxy1.library.usyd.edu.au/conference-proceedings-of-spie/11131/111310L/The-effect-of-dimensionality-reduction-on-signature-based-target-detection/10.1117/12.2529141.short},
	doi = {10.1117/12.2529141},
	abstract = {Target detection is one of the more popular applications of hyperspectral remote sensing. To enhance the detection rate, it is common to do preprocessing to reduce the effects of noise and other forms of undesired interference with the observed spectral signatures. In current earth observing systems, in particular small satellite systems, data rate limitations can make the utilization of sensors with high spectral dimensionality undesirable and even unobtainable. In this paper, the effect of different methods for dimensionality reduction and noise removal has been observed on multiple classical methods for signature matched target detection often used in hyperspectral imaging. The dimensionality reduction differs from resampling in the sense that the original spectral range and resolution can be restored via a linear transformation. This paper suggests that by combining dimensionality reduction and target detection, the resulting data cube has a reduced dimensionality and suppressed undesired effects. The ability to correctly detect spectral phenomena has improved while also achieving reduce data volume. Combining dimensionality reduction and target detection can also reduce the number of computational operations needed in later stages of processing, when operating on the projected space. The observed effects are demonstrated by using simulated and real-world hyperspectral scenes. The real-world scenes are from well-calibrated sensors e.g. AVIRIS, ROSIS, and Hyperion, of classified agricultural and urban areas. The simulated scene is generated using the ASTER library.},
	urldate = {2020-08-15},
	booktitle = {{CubeSats} and {SmallSats} for {Remote} {Sensing} {III}},
	publisher = {International Society for Optics and Photonics},
	author = {Bakken, Sivert and Orlandic, Milica and Johansen, Tor Arne},
	month = aug,
	year = {2019},
	pages = {111310L}
}
@article{danz_miniature_2019,
	title = {Miniature integrated micro-spectrometer array for snap shot multispectral sensing},
	volume = {27},
	copyright = {\&\#169; 2019 Optical Society of America},
	issn = {1094-4087},
	url = {https://www.osapublishing.org/oe/abstract.cfm?uri=oe-27-4-5719},
	doi = {10.1364/OE.27.005719},
	abstract = {An array of micro spectrometers for parallel spectral sensing is designed, set up and tested. It utilizes a planar prism grating combination to obtain an almost linear optical system of 6 mm length only. Arranging such micro spectrometers in an array configuration yields 2\&\#x2019;000 spectrometers when utilizing a common 4/3\&\#x201D; CCD image sensor well adapted to e.g. microscopic image dimensions. The application in microscopic imaging in the 450-900\&\#x00A0;nm spectral range is demonstrated as proof of concept, which can be adapted to massively parallel sensing in the frame of integrated sensor concepts.},
	language = {EN},
	number = {4},
	urldate = {2020-08-15},
	journal = {Optics Express},
	author = {Danz, N. and Höfer, B. and Förster, E. and Flügel-Paul, T. and Harzendorf, T. and Dannberg, P. and Leitel, R. and Kleinle, S. and Brunner, R.},
	month = feb,
	year = {2019},
	note = {Publisher: Optical Society of America},
	keywords = {Detector arrays, Imaging systems, Microspectrometers, Multispectral imaging, Optical design, Optomechanics},
	pages = {5719--5728}
}

@article{oshea_simulation_2020,
	title = {Simulation framework for evaluating lightweight spectral cameras in drone-based aquatic sensing applications},
	volume = {59},
	issn = {1559-128X, 2155-3165},
	url = {https://www.osapublishing.org/abstract.cfm?URI=ao-59-10-C52},
	doi = {10.1364/AO.381564},
	language = {en},
	number = {10},
	urldate = {2020-08-15},
	journal = {Applied Optics},
	author = {O’Shea, Ryan E. and Laney, Samuel R.},
	month = apr,
	year = {2020},
	pages = {C52}
}

@article{stuart_low-cost_2020,
	title = {Low-{Cost} {Hyperspectral} {Imaging} {System}: {Design} and {Testing} for {Laboratory}-{Based} {Environmental} {Applications}},
	volume = {20},
	issn = {1424-8220},
	shorttitle = {Low-{Cost} {Hyperspectral} {Imaging} {System}},
	url = {https://www.mdpi.com/1424-8220/20/11/3293},
	doi = {10.3390/s20113293},
	abstract = {The recent surge in the development of low-cost, miniaturised technologies provides a signiﬁcant opportunity to develop miniaturised hyperspectral imagers at a fraction of the cost of currently available commercial set-ups. This article introduces a low-cost laboratory-based hyperspectral imager developed using commercially available components. The imager is capable of quantitative and qualitative hyperspectral measurements, and it was tested in a variety of laboratory-based environmental applications where it demonstrated its ability to collect data that correlates well with existing datasets. In its current format, the imager is an accurate laboratory measurement tool, with signiﬁcant potential for ongoing future developments. It represents an initial development in accessible hyperspectral technologies, providing a robust basis for future improvements.},
	language = {en},
	number = {11},
	urldate = {2020-08-15},
	journal = {Sensors},
	author = {Stuart, Mary B. and Stanger, Leigh R. and Hobbs, Matthew J. and Pering, Tom D. and Thio, Daniel and McGonigle, Andrew J.S. and Willmott, Jon R.},
	month = jun,
	year = {2020},
	pages = {3293}
}

@article{horstrand_simulation_2019,
	title = {A {Simulation} {Environment} for {Validation} and {Verification} of {Real} {Time} {Hyperspectral} {Processing} {Algorithms} on-{Board} a {UAV}},
	volume = {11},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/11/16/1852},
	doi = {10.3390/rs11161852},
	abstract = {The utilization of hyperspectral imaging sensors has gained a signiﬁcant relevance among many different applications due to their capability for collecting a huge amount of information across the electromagnetic spectrum. These sensors have been traditionally mounted on-board satellites and airplanes in order to extract information from the Earth’s surface. Fortunately, the progressive miniaturization of these sensors during the last lustrum has enabled their use in other remote sensing platforms, such as drones equipped with hyperspectral cameras which bring advantages in terms of higher spatial resolution of the acquired images, more ﬂexible revisit times and lower cost of the ﬂight campaigns. However, when these drones are autonomously ﬂying and taking real-time critical decisions from the information contained in the captured images, it is crucial that the whole process takes place in a safe and predictable manner. In order to deal with this problem, a simulation environment is presented in this work to analyze the virtual behavior of a drone equipped with a pushbroom hyperspectral camera used for assisting harvesting applications, which enables an exhaustive and realistic validation and veriﬁcation of the drone real-time hyperspectral imaging system prior to its launch. To the best of the authors’ knowledge, the proposed environment represents the only solution in the state-of-the-art that allows the virtual veriﬁcation of real-time hyperspectral image processing algorithms under realistic conditions.},
	language = {en},
	number = {16},
	urldate = {2020-08-15},
	journal = {Remote Sensing},
	author = {Horstrand, Pablo and López, José Fco. and López, Sebastián and Leppälampi, Tapio and Pusenius, Markku and Rooker, Martijn},
	month = aug,
	year = {2019},
	pages = {1852}
}

@article{sun_design_2020,
	title = {Design and fabrication of an {InGaAs} focal plane array integrated with linear-array polarization grating},
	volume = {45},
	issn = {0146-9592, 1539-4794},
	url = {https://www.osapublishing.org/abstract.cfm?URI=ol-45-6-1559},
	doi = {10.1364/OL.376110},
	language = {en},
	number = {6},
	urldate = {2020-08-15},
	journal = {Optics Letters},
	author = {Sun, Duo and Feng, Bo and Yang, Bo and Li, Tao and Shao, Xiumei and Li, Xue and Chen, Yifang},
	month = mar,
	year = {2020},
	pages = {1559}
}

@article{wang_optical_2020,
	title = {Optical {Design} of a {Miniaturized} {Airborne} {Push}-{Broom} {Spectrometer}},
	volume = {10},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/10/7/2627},
	doi = {10.3390/app10072627},
	abstract = {Combining the requirements of spectrometers for unmanned aerial vehicle platforms, a miniaturized airborne wide-angle push-broom imaging spectrometer with an Oﬀner conﬁguration is designed. The system comprises an objective lens and an Oﬀner-type spectrometer with a spectral range of 400{\textasciitilde}1000 nm and a spectral resolution of 15 nm. The objective lens and Oﬀner spectrometer are designed in isolation before integration. The front objective lens is an inverted telephoto with a focal length of 13 mm, a relative aperture of 1/4.5, and a ﬁeld of view of 54◦. The frequency of the convex grating in the Oﬀner conﬁguration is 102 LP/mm, and the dispersion width is 2.6 mm. The modulation transfer function of the integrated system is greater than 0.4 at the Nyquist frequency in all spectral bands. To estimate the volume and weight of the system, a preliminary optical–mechanical design scheme is given in this paper. The entire spectrometer has a volume of 130 × 80 × 120 mm and is less than 3 kg, which realizes the miniaturization design of the imaging spectrometer with a wide ﬁeld of view for unmanned aerial vehicle platforms.},
	language = {en},
	number = {7},
	urldate = {2020-08-15},
	journal = {Applied Sciences},
	author = {Wang, Yang and Gu, Zhiyuan and Meng, Xiangyue and Zhang, Lei and Fu, Yuegang},
	month = apr,
	year = {2020},
	pages = {2627}
}

@article{ohtera_nir_2019,
	title = {{NIR} spectrum estimation utilizing a photonic crystal distributed passband-type multiple filter array},
	volume = {58},
	copyright = {\&\#169; 2019 Optical Society of America},
	issn = {2155-3165},
	url = {https://www.osapublishing.org/ao/abstract.cfm?uri=ao-58-12-3166},
	doi = {10.1364/AO.58.003166},
	abstract = {A near-infrared (NIR) spectral sensor consisting of a 25-channel dielectric multi-patterned filter array (MFA) and CCD is proposed and fabricated. The MFA consists of a wavy dielectric multilayer with a gradient layer profile on a silica substrate with surface grating. The incoming NIR spectrum is predicted by Wiener estimation utilizing the MFA\&\#x2019;s spectral responses and a set of training spectral data. Estimation performance is evaluated under various optical shot-noise conditions.},
	language = {EN},
	number = {12},
	urldate = {2020-08-15},
	journal = {Applied Optics},
	author = {Ohtera, Yasuo and Shinoda, Kazuma},
	month = apr,
	year = {2019},
	note = {Publisher: Optical Society of America},
	keywords = {Charge coupled devices, Image sensors, Multispectral imaging, Numerical simulation, Photonic crystals, Remote sensing},
	pages = {3166--3173}
}

@article{yuan_optical_2019,
	title = {Optical design and evaluation of airborne prism-grating imaging spectrometer},
	volume = {27},
	copyright = {\&\#169; 2019 Optical Society of America},
	issn = {1094-4087},
	url = {https://www.osapublishing.org/oe/abstract.cfm?uri=oe-27-13-17686},
	doi = {10.1364/OE.27.017686},
	abstract = {We have focused on the optical form that is low cost while maintaining high performance for airborne application. We report the optical design as well as the alignment and test results for a push-broom imaging spectrometer. The smart architecture of the prism-grating based spectrometer ensures high uniformity and image quality. Moreover, an effective method for aligning the spectrometer is also proposed. The results of laboratory-based optical tests and a flight test confirm the easy manufacture and excellent performance. Thus, the proposed system should be suitable for use as a hyperspectral instrument that can be loaded onto airborne and unmanned aerial vehicles.},
	language = {EN},
	number = {13},
	urldate = {2020-08-15},
	journal = {Optics Express},
	author = {Yuan, Liyin and Xie, Jia’nan and He, Zhiping and Wang, Yueming and Wang, Jianyu},
	month = jun,
	year = {2019},
	note = {Publisher: Optical Society of America},
	keywords = {Grating prisms, Image quality, Optical design, Optical testing, Optomechanical design, Volume gratings},
	pages = {17686--17700}
}

@article{hobbs_developing_2020,
	title = {Developing a spectral pipeline using open source software and low-cost hardware for material identification},
	volume = {41},
	issn = {0143-1161},
	url = {https://doi.org/10.1080/01431161.2019.1693075},
	doi = {10.1080/01431161.2019.1693075},
	abstract = {The ability to access, design and create low cost sensors capable of returning scientifically useful data has led to an exponential increase in citizen science, education and environmental monitoring groups. Low-cost spectroscopy is one such application and mobile phone camera-based instruments have been used in pollution monitoring, medical applications in developing countries and vegetation analysis. Can such an instrument be developed and tested to assist with automated detection of materials, possibly from space? We tested two spectrometer designs inside a two unit (2U) cubesat frame against a series of materials exhibiting phenomenology in the visible/near infrared (Vis/NIR) portion of the spectrum and vegetation groups. This was conducted in order to determine whether open source designs were capable of discriminating against similar materials, such as types of vegetation or types of iron-rich minerals. A spectral pipeline was created using open source programming software that was capable of converting raw sensor data into spectra, comparing samples of interest against a spectral library and returning an identification result with a confidence interval. We found that low-cost hardware sensitive to NIR and freely available software were able to identify types of materials in the study set, enabling applications in citizen science, education and outreach or even low-cost near-space research.},
	number = {7},
	urldate = {2020-08-15},
	journal = {International Journal of Remote Sensing},
	author = {Hobbs, S. W. and Paull, D. J. and Haythorpe, J. and McDougall, T.},
	month = apr,
	year = {2020},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01431161.2019.1693075},
	pages = {2517--2543}
}

@article{wang_leafspec_2020,
	title = {{LeafSpec}: {An} accurate and portable hyperspectral corn leaf imager},
	volume = {169},
	issn = {0168-1699},
	shorttitle = {{LeafSpec}},
	url = {http://www.sciencedirect.com/science/article/pii/S0168169919303709},
	doi = {10.1016/j.compag.2019.105209},
	abstract = {Hyperspectral imaging (HSI) technology has been widely applied in industry and academia for plant phenotyping. However, most HSI systems are large and expensive, making it challenging to benefit more people. The overall goal of this study was to develop a portable and low-cost hyperspectral imaging handheld device (named LeafSpec) with even improved measurement quality compared with traditional HSI systems for crop leaves imaging. The hardware of LeafSpec device was comprised of a push-broom hyperspectral camera (HSC), leaf scanner with an encoder system for leaf position information, a lightbox as an intensive and uniform beam lighting source, and an ARM-based microcontroller. In each scanning, a smooth and clear hyperspectral image of the entire leaf was obtained by quickly sliding LeafSpec across the leaf from the beginning to tip. Each measurement was geo-referenced by sending processed data to a smartphone and combining it with the GPS location and time information before uploading to a Geography Information System (GIS) with Digital Ag Map Services and internet connection. After calibration, the HSC’s imaging results were highly consistent with a commercialized hyperspectral camera. In the field test in the summer of 2018, LeafSpec was able to detect the difference between two nitrogen treatments of corn plants in each genotype, as well as the differences between three genotypes in high nitrogen treatment, and the difference between two genotypes in low nitrogen treatment before it was visible to human eyes. In the greenhouse test in the spring of 2019, LeafSpec predicted nitrogen content and relative water content with R2 of 0.880 and 0.771, RMSE of 0.265 and 0.049, respectively. Generally, LeafSpec is an easy-to-use and low-cost crop phenotyping sensor with improved measurement accuracy, which could benefit more people in plant science research and agriculture production.},
	language = {en},
	urldate = {2020-08-15},
	journal = {Computers and Electronics in Agriculture},
	author = {Wang, Liangju and Jin, Jian and Song, Zhihang and Wang, Jialei and Zhang, Libo and Rehman, Tanzeel U. and Ma, Dongdong and Carpenter, Neal R. and Tuinstra, Mitchell R.},
	month = feb,
	year = {2020},
	keywords = {Crop leaf scanner, Handheld sensor, Hyperspectral imaging, LeafSpec, Plant phenotyping},
	pages = {105209}
}

@article{cai_handheld_2020,
	title = {Handheld four-dimensional optical sensor},
	volume = {203},
	issn = {0030-4026},
	url = {http://www.sciencedirect.com/science/article/pii/S003040261931900X},
	doi = {10.1016/j.ijleo.2019.164001},
	abstract = {Spectral and imaging systems enable retrieval of the molecular and surface profile information of objects of interest. Camera has become an indispensable device in everyday life to capture images for surface profile investigation. However up to now, spectral data are still neglected even though we receive this information most of the time. In this work, we developed a handheld four-dimensional optical sensor by combining a lightweight imaging spectrometer and a binocular camera. Based on this compact system, we can acquire spatial images, depth information and spectral data simultaneously. This technology can be applied to any kind of image capture equipment. It can be used to remotely and quickly collect spectral information and spatial images synchronously and has important value for object classification.},
	language = {en},
	urldate = {2020-08-15},
	journal = {Optik},
	author = {Cai, Fuhong and Wang, Tianci and Wu, Jingjin and Zhang, Xiyu},
	month = feb,
	year = {2020},
	keywords = {Four-dimensional, Handheld, Imaging spectrometer},
	pages = {164001}
}

@article{cai_design_2020,
	title = {The design and implementation of portable rotational scanning imaging spectrometer},
	volume = {459},
	issn = {0030-4018},
	url = {http://www.sciencedirect.com/science/article/pii/S0030401819310697},
	doi = {10.1016/j.optcom.2019.125016},
	abstract = {Imaging spectrometer has a promising application prospect in the field of ecological environment monitoring. Nowadays, the scanning mode of imaging spectrometer is mainly push-broom and snap-shoot. However, few studies focus on using rotational scanning mode to carry out spectral scanning for imaging spectrometer. In this paper, we devise a portable rotating scanning spectrometer, which can be installed on a small mechanical and electrical equipment for rotating scan. During the scanning process, the orientation of the spectral axis of the spectral image is not fixed. In our work, we used Hough algorithm to analyse the line angle in spectral images, and then corrected all spectral images by reverse rotation. From the corrected image, we can obtain spectral data of scanned target object. Furthermore, we design a reconstruction algorithm, which can reconstruct a 2-D spatial image based on the spectral images. Although the quality of the spatial image is affected by instability of the system, our experimental results also demonstrate that the system can be used to obtain spectral cubes i.e. 2-D spatial and 1-D spectral information. This system can be used for spectral sensing for any objects of interested without the help of precise electromechanical equipment. Therefore, this system has the potential of being improved into an ultra-compact imaging spectrometer and used in some complex application environments, such as endoscopic imaging.},
	language = {en},
	urldate = {2020-08-15},
	journal = {Optics Communications},
	author = {Cai, Fuhong and Chen, Jie and Xie, Xiaofeng and Xie, Jun},
	month = mar,
	year = {2020},
	keywords = {Image reconstruction, Imaging spectrometer, Rotational scanning, Spectral image},
	pages = {125016}
}

@article{yi_hadamard_2020,
	title = {Hadamard transform-based hyperspectral imaging using a single-pixel detector},
	volume = {28},
	copyright = {\&\#169; 2020 Optical Society of America},
	issn = {1094-4087},
	url = {https://www.osapublishing.org/oe/abstract.cfm?uri=oe-28-11-16126},
	doi = {10.1364/OE.390490},
	abstract = {In this paper, a single-pixel hyperspectral imager is developed based on the Hadamard transformation. The imager\&\#x2019;s design, fabrication, signal processing method, and experimental results are discussed. The single-pixel hyperspectral imager works in pushbroom mode and employs both spatial encoding and spectral encoding to acquire the hyperspectral data cube. Hadamard encoding patterns, which are known for their multiplexing advantage to achieve high signal-to-noise ratio (SNR), are used in both encoding schemes. A digital micromirror device (DMD) from Texas Instruments (TI) is used for slow spatial encoding and a resonant scanning mirror in combination with a fixed Hadamard mask is used for fast spectral encoding. In addition, the pushbroom operation can be achieved internally by spatially shifting the location of the Hadamard encoded slit on the DMD, thus the imager is able to acquire 3D data cubes without the need to scan it across the object. Although our experimental results demonstrate the hyperspectral data cubes of various objects over a 450\&\#x2005;nm \&\#x223C; 750\&\#x2005;nm visible spectral range, the proposed imager can be easily configured to be used at other wavelengths due to the single-pixel detection mechanism used.},
	language = {EN},
	number = {11},
	urldate = {2020-08-15},
	journal = {Optics Express},
	author = {Yi, Qi and Heng, Lim Zi and Liang, Li and Guangcan, Zhou and Siong, Chau Fook and Guangya, Zhou},
	month = may,
	year = {2020},
	note = {Publisher: Optical Society of America},
	keywords = {Digital micromirror devices, Fourier transform infrared spectroscopy, Imaging techniques, Medical imaging, Optical components, Spatial light modulators},
	pages = {16126--16139}
}

@article{qi_single-pixel_2020,
	title = {A single-pixel hyperspectral imager using two-stage {Hadamard} encoding},
	volume = {470},
	issn = {0030-4018},
	url = {http://www.sciencedirect.com/science/article/pii/S0030401820303199},
	doi = {10.1016/j.optcom.2020.125813},
	abstract = {This paper presents a hyperspectral imaging approach using a single-pixel detector. The system consists of a two-stage encoding system based on the concept of Hadamard transform. In contrast with conventional hyperspectral imaging methods where wavelength filters or Fourier spectroscopy is usually adopted, the spectral imaging system in this design uses an encoded slit, a resonant scanning mirror, and a fixed encoder mask to reconstruct the spectral image. The proposed method provides a novel way to set up an easily-controllable single-pixel approach that allows the imager to operate at any wavelength. We present a complete single-pixel hyperspectral imaging system with experimental results to demonstrate its working performance.},
	language = {en},
	urldate = {2020-08-15},
	journal = {Optics Communications},
	author = {Qi, Yi and Li, Liang and Zhou, Guangcan and Lim, Zi Heng and Chau, Fook Siong and Zhou, Guangya},
	month = sep,
	year = {2020},
	keywords = {Hadamard transform, Hyperspectral imaging, Single-pixel imaging},
	pages = {125813}
}

@article{herrala_imaging_1996,
	title = {Imaging spectrograph and camera solutions for industrial applications},
	volume = {10},
	issn = {0218-0014},
	url = {https://www-worldscientific-com.ezproxy1.library.usyd.edu.au/doi/abs/10.1142/S0218001496000050},
	doi = {10.1142/S0218001496000050},
	abstract = {An imaging spectrometer instrument based on a prism-grating-prism (PGP) element as the dispersive component and advanced camera solutions for on-line applications are presented. The PGP element uses a volume type holographic plane transmission grating made of dichromated gelatin (DCG). Currently, spectrographs have been realized for the 400–1050 nm region but applicable spectral region of the PGP is 380–1800 nm. Spectral resolution is typically between 1.5 and 5 nm. The on-axis optical configuration and simple rugged tubular optomechanical construction of the spectrograph provides a good image quality and resistance to harsh environmental conditions. Spectrograph optics are designed to be interfaced to any standard CCD camera. Special camera structures and operating modes can be used for applications requiring on-line data interpretation and process control.},
	number = {01},
	urldate = {2020-08-15},
	journal = {International Journal of Pattern Recognition and Artificial Intelligence},
	author = {Herrala, Esko and Okkonen, Jukka},
	month = feb,
	year = {1996},
	note = {Publisher: World Scientific Publishing Co.},
	pages = {43--54}
}

@inproceedings{antila_spectral_2012,
	title = {Spectral imaging device based on a tuneable {MEMS} {Fabry}-{Perot} interferometer},
	volume = {8374},
	url = {https://www-spiedigitallibrary-org.ezproxy1.library.usyd.edu.au/conference-proceedings-of-spie/8374/83740F/Spectral-imaging-device-based-on-a-tuneable-MEMS-Fabry-Perot/10.1117/12.919271.short},
	doi = {10.1117/12.919271},
	abstract = {The trend in the development of single-point spectrometric sensors is miniaturization, cost reduction and increase of functionality and versatility. MEMS Fabry-Perot interferometers (FPI) have been proven to meet many of these requirements in the form of miniaturized spectrometer modules and tuneable light sources. Recent development of MEMS FPI devices based on ALD thin film structures potentially addresses all of these main trends. In this paper we present a device and first measurement results of a small imaging spectrometer utilizing a 1.5 mm tuneable MEMS FPI filter working in the visible range of 430-580 nm. The construction of the instrument and the properties of the tuneable filter are explained especially from imaging requirements point of view.},
	urldate = {2020-08-15},
	booktitle = {Next-{Generation} {Spectroscopic} {Technologies} {V}},
	publisher = {International Society for Optics and Photonics},
	author = {Antila, Jarkko and Mannila, Rami and Kantojärvi, Uula and Holmlund, Christer and Rissanen, Anna and Näkki, Ismo and Ollila, Jyrki and Saari, Heikki},
	month = may,
	year = {2012},
	pages = {83740F}
}

@article{sigernes_it_2018,
	title = {Do it yourself hyperspectral imager for handheld to airborne operations},
	volume = {26},
	issn = {1094-4087},
	url = {https://www.osapublishing.org/abstract.cfm?URI=oe-26-5-6021},
	doi = {10.1364/OE.26.006021},
	abstract = {This study describes rapid prototype construction of small and lightweight push broom Hyper Spectral Imagers (HSI). The dispersive element housings are printed by a thermoplastic 3D printer combined with S-mount optical components and commercial offthe-shelf camera heads. Four models with a mass less than 200 g are presented with a spectral range in the visible to the near-infrared part of the electromagnetic spectrum. The bandpass is in the range from 1.4 - 5 nm. Three test experiments with motorized gimbals to stabilize attitude show that the instruments are capable of push broom spectral imaging from various platforms, including airborne drone to handheld operations.},
	language = {en},
	number = {5},
	urldate = {2020-08-06},
	journal = {Optics Express},
	author = {Sigernes, Fred and Syrjäsuo, Mikko and Storvold, Rune and Fortuna, João and Grøtte, Mariusz Eivind and Johansen, Tor Arne},
	month = mar,
	year = {2018},
	pages = {6021}
}

@article{stuart_hyperspectral_2019,
	title = {Hyperspectral {Imaging} in {Environmental} {Monitoring}: {A} {Review} of {Recent} {Developments} and {Technological} {Advances} in {Compact} {Field} {Deployable} {Systems}},
	volume = {19},
	issn = {1424-8220},
	shorttitle = {Hyperspectral {Imaging} in {Environmental} {Monitoring}},
	url = {https://www.mdpi.com/1424-8220/19/14/3071},
	doi = {10.3390/s19143071},
	abstract = {The development and uptake of ﬁeld deployable hyperspectral imaging systems within environmental monitoring represents an exciting and innovative development that could revolutionize a number of sensing applications in the coming decades. In this article we focus on the successful miniaturization and improved portability of hyperspectral sensors, covering their application both from aerial and ground-based platforms in a number of environmental application areas, highlighting in particular the recent implementation of low-cost consumer technology in this context. At present, these devices largely complement existing monitoring approaches, however, as technology continues to improve, these units are moving towards reaching a standard suitable for stand-alone monitoring in the not too distant future. As these low-cost and light-weight devices are already producing scientiﬁc grade results, they now have the potential to signiﬁcantly improve accessibility to hyperspectral monitoring technology, as well as vastly proliferating acquisition of such datasets.},
	language = {en},
	number = {14},
	urldate = {2020-08-04},
	journal = {Sensors},
	author = {{Stuart} and {McGonigle} and {Willmott}},
	month = jul,
	year = {2019},
	pages = {3071}
}